{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary as summary\n",
    "import onnx\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from python.craftdet.models import *\n",
    "from python.craftdet.models.utils import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Craftdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_net = basenet.BaseNet()\n",
    "# summary.summary(base_net, (3, 256, 256), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(base_net.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export basenet to onnx\n",
    "# import torch\n",
    "\n",
    "\n",
    "# torch_model = BaseNet(freeze=False, pretrained=False)\n",
    "\n",
    "# torch_input = torch.randn(1, 3, 256, 256)\n",
    "# onnx_program = torch.onnx.export(torch_model, torch_input, \"models/basenet.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onnx_model = onnx.load('models/basenet.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onnx_model.graph.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources = [\n",
    "#     torch.rand([1024, 16, 16]),\n",
    "#     torch.rand([512, 16, 16]),\n",
    "#     torch.rand([512, 32, 32]),\n",
    "#     torch.rand([256, 64, 64]),\n",
    "#     torch.rand([128, 128, 128])\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 512, 512]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 512, 512]             128\n",
      "              ReLU-3         [-1, 64, 512, 512]               0\n",
      "            Conv2d-4         [-1, 64, 512, 512]          36,928\n",
      "       BatchNorm2d-5         [-1, 64, 512, 512]             128\n",
      "              ReLU-6         [-1, 64, 512, 512]               0\n",
      "         MaxPool2d-7         [-1, 64, 256, 256]               0\n",
      "            Conv2d-8        [-1, 128, 256, 256]          73,856\n",
      "       BatchNorm2d-9        [-1, 128, 256, 256]             256\n",
      "             ReLU-10        [-1, 128, 256, 256]               0\n",
      "           Conv2d-11        [-1, 128, 256, 256]         147,584\n",
      "      BatchNorm2d-12        [-1, 128, 256, 256]             256\n",
      "             ReLU-13        [-1, 128, 256, 256]               0\n",
      "        MaxPool2d-14        [-1, 128, 128, 128]               0\n",
      "           Conv2d-15        [-1, 256, 128, 128]         295,168\n",
      "      BatchNorm2d-16        [-1, 256, 128, 128]             512\n",
      "             ReLU-17        [-1, 256, 128, 128]               0\n",
      "           Conv2d-18        [-1, 256, 128, 128]         590,080\n",
      "      BatchNorm2d-19        [-1, 256, 128, 128]             512\n",
      "             ReLU-20        [-1, 256, 128, 128]               0\n",
      "           Conv2d-21        [-1, 256, 128, 128]         590,080\n",
      "      BatchNorm2d-22        [-1, 256, 128, 128]             512\n",
      "             ReLU-23        [-1, 256, 128, 128]               0\n",
      "        MaxPool2d-24          [-1, 256, 64, 64]               0\n",
      "           Conv2d-25          [-1, 512, 64, 64]       1,180,160\n",
      "      BatchNorm2d-26          [-1, 512, 64, 64]           1,024\n",
      "             ReLU-27          [-1, 512, 64, 64]               0\n",
      "           Conv2d-28          [-1, 512, 64, 64]       2,359,808\n",
      "      BatchNorm2d-29          [-1, 512, 64, 64]           1,024\n",
      "             ReLU-30          [-1, 512, 64, 64]               0\n",
      "           Conv2d-31          [-1, 512, 64, 64]       2,359,808\n",
      "      BatchNorm2d-32          [-1, 512, 64, 64]           1,024\n",
      "             ReLU-33          [-1, 512, 64, 64]               0\n",
      "        MaxPool2d-34          [-1, 512, 32, 32]               0\n",
      "           Conv2d-35          [-1, 512, 32, 32]       2,359,808\n",
      "      BatchNorm2d-36          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-37          [-1, 512, 32, 32]               0\n",
      "           Conv2d-38          [-1, 512, 32, 32]       2,359,808\n",
      "      BatchNorm2d-39          [-1, 512, 32, 32]           1,024\n",
      "        MaxPool2d-40          [-1, 512, 32, 32]               0\n",
      "           Conv2d-41         [-1, 1024, 32, 32]       4,719,616\n",
      "           Conv2d-42         [-1, 1024, 32, 32]       1,049,600\n",
      "          BaseNet-43  [[-1, 1024, 32, 32], [-1, 512, 32, 32], [-1, 512, 64, 64], [-1, 256, 128, 128], [-1, 128, 256, 256]]               0\n",
      "           Conv2d-44          [-1, 512, 32, 32]         786,944\n",
      "      BatchNorm2d-45          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-46          [-1, 512, 32, 32]               0\n",
      "           Conv2d-47          [-1, 256, 32, 32]       1,179,904\n",
      "      BatchNorm2d-48          [-1, 256, 32, 32]             512\n",
      "             ReLU-49          [-1, 256, 32, 32]               0\n",
      "       DoubleConv-50          [-1, 256, 32, 32]               0\n",
      "           Conv2d-51          [-1, 256, 64, 64]         196,864\n",
      "      BatchNorm2d-52          [-1, 256, 64, 64]             512\n",
      "             ReLU-53          [-1, 256, 64, 64]               0\n",
      "           Conv2d-54          [-1, 128, 64, 64]         295,040\n",
      "      BatchNorm2d-55          [-1, 128, 64, 64]             256\n",
      "             ReLU-56          [-1, 128, 64, 64]               0\n",
      "       DoubleConv-57          [-1, 128, 64, 64]               0\n",
      "           Conv2d-58        [-1, 128, 128, 128]          49,280\n",
      "      BatchNorm2d-59        [-1, 128, 128, 128]             256\n",
      "             ReLU-60        [-1, 128, 128, 128]               0\n",
      "           Conv2d-61         [-1, 64, 128, 128]          73,792\n",
      "      BatchNorm2d-62         [-1, 64, 128, 128]             128\n",
      "             ReLU-63         [-1, 64, 128, 128]               0\n",
      "       DoubleConv-64         [-1, 64, 128, 128]               0\n",
      "           Conv2d-65         [-1, 64, 256, 256]          12,352\n",
      "      BatchNorm2d-66         [-1, 64, 256, 256]             128\n",
      "             ReLU-67         [-1, 64, 256, 256]               0\n",
      "           Conv2d-68         [-1, 32, 256, 256]          18,464\n",
      "      BatchNorm2d-69         [-1, 32, 256, 256]              64\n",
      "             ReLU-70         [-1, 32, 256, 256]               0\n",
      "       DoubleConv-71         [-1, 32, 256, 256]               0\n",
      "           Conv2d-72         [-1, 32, 256, 256]           9,248\n",
      "             ReLU-73         [-1, 32, 256, 256]               0\n",
      "           Conv2d-74         [-1, 32, 256, 256]           9,248\n",
      "             ReLU-75         [-1, 32, 256, 256]               0\n",
      "           Conv2d-76         [-1, 16, 256, 256]           4,624\n",
      "             ReLU-77         [-1, 16, 256, 256]               0\n",
      "           Conv2d-78         [-1, 16, 256, 256]             272\n",
      "             ReLU-79         [-1, 16, 256, 256]               0\n",
      "           Conv2d-80          [-1, 2, 256, 256]              34\n",
      "================================================================\n",
      "Total params: 20,770,466\n",
      "Trainable params: 20,770,466\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.00\n",
      "Forward/backward pass size (MB): 2081.00\n",
      "Params size (MB): 79.23\n",
      "Estimated Total Size (MB): 2163.23\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "basenet = basenet.BaseNet(pretrained=False, freeze=False)\n",
    "craft_net = craftnet.CraftNet(basenet=basenet)\n",
    "\n",
    "summary.summary(craft_net, (3, 512, 512), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor) -> Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]:\n",
      "  slice5 = self.slice5\n",
      "  slice4 = self.slice4\n",
      "  slice3 = self.slice3\n",
      "  slice2 = self.slice2\n",
      "  slice1 = self.slice1\n",
      "  _0 = (slice2).forward((slice1).forward(x, ), )\n",
      "  _1, _2, = _0\n",
      "  _3, _4, = (slice3).forward(_1, )\n",
      "  _5, _6, = (slice4).forward(_3, )\n",
      "  _7 = ((slice5).forward(_5, ), _5, _6, _4, _2)\n",
      "  return _7\n",
      "\n",
      "def forward(self,\n",
      "    x: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  _0 = __torch__.torch.nn.functional.___torch_mangle_317.interpolate\n",
      "  basenet = self.basenet\n",
      "  sources = (basenet).forward(x, )\n",
      "  y = torch.cat([(sources)[0], (sources)[1]], 1)\n",
      "  upconv1 = self.upconv1\n",
      "  y0 = (upconv1).forward(y, )\n",
      "  _1 = torch.slice(torch.size((sources)[2]), 2)\n",
      "  y1 = _0(y0, _1, None, \"bilinear\", False, None, False, )\n",
      "  y2 = torch.cat([y1, (sources)[2]], 1)\n",
      "  upconv2 = self.upconv2\n",
      "  y3 = (upconv2).forward(y2, )\n",
      "  _2 = torch.slice(torch.size((sources)[3]), 2)\n",
      "  y4 = _0(y3, _2, None, \"bilinear\", False, None, False, )\n",
      "  y5 = torch.cat([y4, (sources)[3]], 1)\n",
      "  upconv3 = self.upconv3\n",
      "  y6 = (upconv3).forward(y5, )\n",
      "  _3 = torch.slice(torch.size((sources)[4]), 2)\n",
      "  y7 = _0(y6, _3, None, \"bilinear\", False, None, False, )\n",
      "  y8 = torch.cat([y7, (sources)[4]], 1)\n",
      "  upconv4 = self.upconv4\n",
      "  feature = (upconv4).forward(y8, )\n",
      "  conv_cls = self.conv_cls\n",
      "  y9 = (conv_cls).forward(feature, )\n",
      "  _4 = (torch.permute(y9, [0, 2, 3, 1]), feature)\n",
      "  return _4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/jit/_script.py:1277: UserWarning: `optimize` is deprecated and has no effect. Use `with torch.jit.optimized_execution() instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "torch_input = torch.randn((1, 3, 512, 512), dtype=torch.float32)\n",
    "craft_net.basenet = torch.jit.script(craft_net.basenet, torch_input)\n",
    "craft_net_trace = torch.jit.script(craft_net, torch_input)\n",
    "print(craft_net_trace.basenet.code)\n",
    "print(craft_net_trace.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "IMAGE_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "craft: str = './weights/craft/mlt25k.pth'\n",
    "craft_net = load_model(CraftNet(basenet), craft, use_cuda)\n",
    "torch_input = torch.randn((1, 3, IMAGE_SIZE, IMAGE_SIZE), device='cuda' if use_cuda else 'cpu')\n",
    "onnx_program = torch.onnx.export(craft_net, torch_input, \"models/craftnet.onnx\")\n",
    "# onnx_program.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "refiner: str = './weights/craft/refinerCTW1500.pth'\n",
    "refine_net = load_model(RefineNet(), refiner, use_cuda)\n",
    "torch_input = (\n",
    "    torch.randn((1, IMAGE_SIZE, IMAGE_SIZE, 2), device='cuda' if use_cuda else 'cpu'),\n",
    "    torch.randn((1, 32, IMAGE_SIZE, IMAGE_SIZE), device='cuda' if use_cuda else 'cpu')\n",
    ")\n",
    "onnx_program = torch.onnx.export(refine_net, torch_input, \"models/retinet.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vietocr.tool.predictor import Predictor\n",
    "from vietocr.tool.config import Cfg\n",
    "\n",
    "config = Cfg.load_config_from_name('vgg_seq2seq')\n",
    "config['weights'] = str(Path(os.getcwd() + '/weights/ocr/vgg_seq2seq.pth').expanduser().resolve())\n",
    "config['device'] = 'cuda:0'\n",
    "# ocr = Predictor(config)\n",
    "save_ocr_path = Path(os.getcwd()+ \"/prediction/ocr\").expanduser().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab': 'aAàÀảẢãÃáÁạẠăĂằẰẳẲẵẴắẮặẶâÂầẦẩẨẫẪấẤậẬbBcCdDđĐeEèÈẻẺẽẼéÉẹẸêÊềỀểỂễỄếẾệỆfFgGhHiIìÌỉỈĩĨíÍịỊjJkKlLmMnNoOòÒỏỎõÕóÓọỌôÔồỒổỔỗỖốỐộỘơƠờỜởỞỡỠớỚợỢpPqQrRsStTuUùÙủỦũŨúÚụỤưƯừỪửỬữỮứỨựỰvVwWxXyYỳỲỷỶỹỸýÝỵỴzZ0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ ',\n",
       " 'device': 'cuda:0',\n",
       " 'seq_modeling': 'seq2seq',\n",
       " 'transformer': {'encoder_hidden': 256,\n",
       "  'decoder_hidden': 256,\n",
       "  'img_channel': 256,\n",
       "  'decoder_embedded': 256,\n",
       "  'dropout': 0.1},\n",
       " 'optimizer': {'max_lr': 0.001, 'pct_start': 0.1},\n",
       " 'trainer': {'batch_size': 32,\n",
       "  'print_every': 200,\n",
       "  'valid_every': 4000,\n",
       "  'iters': 100000,\n",
       "  'export': './weights/transformerocr.pth',\n",
       "  'checkpoint': './checkpoint/transformerocr_checkpoint.pth',\n",
       "  'log': './train.log',\n",
       "  'metrics': None},\n",
       " 'dataset': {'name': 'data',\n",
       "  'data_root': './img/',\n",
       "  'train_annotation': 'annotation_train.txt',\n",
       "  'valid_annotation': 'annotation_val_small.txt',\n",
       "  'image_height': 32,\n",
       "  'image_min_width': 32,\n",
       "  'image_max_width': 512},\n",
       " 'dataloader': {'num_workers': 3, 'pin_memory': True},\n",
       " 'aug': {'image_aug': True, 'masked_language_model': True},\n",
       " 'predictor': {'beamsearch': False},\n",
       " 'quiet': False,\n",
       " 'pretrain': 'https://vocr.vn/data/vietocr/vgg_seq2seq.pth',\n",
       " 'weights': '/home/hungnq/hungnq/craftdet/weights/ocr/vgg_seq2seq.pth',\n",
       " 'backbone': 'vgg19_bn',\n",
       " 'cnn': {'ss': [[2, 2], [2, 2], [2, 1], [2, 1], [1, 1]],\n",
       "  'ks': [[2, 2], [2, 2], [2, 1], [2, 1], [1, 1]],\n",
       "  'hidden': 256}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vietocr.model.transformerocr import VietOCR\n",
    "from vietocr.model.vocab import Vocab\n",
    "\n",
    "vocab = Vocab(config['vocab'])\n",
    "device = config['device']\n",
    "\n",
    "model = VietOCR(len(vocab),\n",
    "    config['backbone'],\n",
    "    config['cnn'], \n",
    "    config['transformer'],\n",
    "    config['seq_modeling']\n",
    ")\n",
    "model.load_state_dict(torch.load(config['weights'] , map_location=torch.device(config['device'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "torch.Size([10, 1, 233])\n",
      "torch.Size([10, 256])\n",
      "torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "eos_token = 1\n",
    "translated_sentence = [[0]*10]\n",
    "char_probs = [[0]]\n",
    "memory = (torch.zeros(10, 256), torch.zeros(1, 10, 512))\n",
    "max_length = 0\n",
    "\n",
    "while max_length <= 128 and not all(np.any(np.asarray(translated_sentence).T==eos_token, axis=1)):\n",
    "    tgt_inp = torch.LongTensor(translated_sentence).to(device)\n",
    "    print(tgt_inp.shape)\n",
    "    output, memory = model.transformer.forward_decoder(tgt_inp, memory)\n",
    "    print(output.shape)\n",
    "    print(memory[0].shape)\n",
    "    print(memory[1].shape)\n",
    "    break\n",
    "    max_length += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(torch.randn((1, 3, 256, 256)), rch.randint(0, 100, (1, 2)), torch.randint(0, 100, (1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%IMAGE : Float(*, 3, 512, 512, strides=[786432, 262144, 512, 1], requires_grad=0, device=cpu),\n",
      "      %model.last_conv_1x1.weight : Float(256, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %model.last_conv_1x1.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n",
      "      %onnx::Conv_180 : Float(64, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_181 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_183 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_184 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_186 : Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_187 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_189 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_190 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_192 : Float(256, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_193 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_195 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_196 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_198 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_199 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_201 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_202 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_204 : Float(512, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_205 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_207 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_208 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_210 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_211 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_213 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_214 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_216 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_217 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_219 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_220 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_222 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_223 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_225 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_226 : Float(512, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %/model/features/features.0/Conv_output_0 : Float(*, 64, 512, 512, strides=[16777216, 262144, 512, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.0/Conv\"](%IMAGE, %onnx::Conv_180, %onnx::Conv_181), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.0 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/model/features/features.2/Relu_output_0 : Float(*, 64, 512, 512, strides=[16777216, 262144, 512, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/model/features/features.2/Relu\"](%/model/features/features.0/Conv_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.2 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/functional.py:1469:0\n",
      "  %/model/features/features.3/Conv_output_0 : Float(*, 64, 512, 512, strides=[16777216, 262144, 512, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.3/Conv\"](%/model/features/features.2/Relu_output_0, %onnx::Conv_183, %onnx::Conv_184), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.3 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/model/features/features.5/Relu_output_0 : Float(*, 64, 512, 512, strides=[16777216, 262144, 512, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/model/features/features.5/Relu\"](%/model/features/features.3/Conv_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.5 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/functional.py:1469:0\n",
      "  %/model/features/features.6/AveragePool_output_0 : Float(*, 64, 256, 256, strides=[4194304, 65536, 256, 1], requires_grad=0, device=cpu) = onnx::AveragePool[ceil_mode=0, count_include_pad=1, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/model/features/features.6/AveragePool\"](%/model/features/features.5/Relu_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.pooling.AvgPool2d::features.6 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/pooling.py:635:0\n",
      "  %/model/features/features.7/Conv_output_0 : Float(*, 128, 256, 256, strides=[8388608, 65536, 256, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.7/Conv\"](%/model/features/features.6/AveragePool_output_0, %onnx::Conv_186, %onnx::Conv_187), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.7 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/model/features/features.9/Relu_output_0 : Float(*, 128, 256, 256, strides=[8388608, 65536, 256, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/model/features/features.9/Relu\"](%/model/features/features.7/Conv_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.9 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/functional.py:1469:0\n",
      "  %/model/features/features.10/Conv_output_0 : Float(*, 128, 256, 256, strides=[8388608, 65536, 256, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.10/Conv\"](%/model/features/features.9/Relu_output_0, %onnx::Conv_189, %onnx::Conv_190), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.10 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/model/features/features.12/Relu_output_0 : Float(*, 128, 256, 256, strides=[8388608, 65536, 256, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/model/features/features.12/Relu\"](%/model/features/features.10/Conv_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.12 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/functional.py:1469:0\n",
      "  %/model/features/features.13/AveragePool_output_0 : Float(*, 128, 128, 128, strides=[2097152, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::AveragePool[ceil_mode=0, count_include_pad=1, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/model/features/features.13/AveragePool\"](%/model/features/features.12/Relu_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.pooling.AvgPool2d::features.13 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/pooling.py:635:0\n",
      "  %/model/features/features.14/Conv_output_0 : Float(*, 256, 128, 128, strides=[4194304, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.14/Conv\"](%/model/features/features.13/AveragePool_output_0, %onnx::Conv_192, %onnx::Conv_193), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.14 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/model/features/features.16/Relu_output_0 : Float(*, 256, 128, 128, strides=[4194304, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/model/features/features.16/Relu\"](%/model/features/features.14/Conv_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.16 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/functional.py:1469:0\n",
      "  %/model/features/features.17/Conv_output_0 : Float(*, 256, 128, 128, strides=[4194304, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.17/Conv\"](%/model/features/features.16/Relu_output_0, %onnx::Conv_195, %onnx::Conv_196), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.17 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/model/features/features.19/Relu_output_0 : Float(*, 256, 128, 128, strides=[4194304, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/model/features/features.19/Relu\"](%/model/features/features.17/Conv_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.19 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/functional.py:1469:0\n",
      "  %/model/features/features.20/Conv_output_0 : Float(*, 256, 128, 128, strides=[4194304, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.20/Conv\"](%/model/features/features.19/Relu_output_0, %onnx::Conv_198, %onnx::Conv_199), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.20 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/model/features/features.22/Relu_output_0 : Float(*, 256, 128, 128, strides=[4194304, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/model/features/features.22/Relu\"](%/model/features/features.20/Conv_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.22 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/functional.py:1469:0\n",
      "  %/model/features/features.23/Conv_output_0 : Float(*, 256, 128, 128, strides=[4194304, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.23/Conv\"](%/model/features/features.22/Relu_output_0, %onnx::Conv_201, %onnx::Conv_202), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.23 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/model/features/features.25/Relu_output_0 : Float(*, 256, 128, 128, strides=[4194304, 16384, 128, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/model/features/features.25/Relu\"](%/model/features/features.23/Conv_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.25 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/functional.py:1469:0\n",
      "  %/model/features/features.26/AveragePool_output_0 : Float(*, 256, 64, 128, strides=[2097152, 8192, 128, 1], requires_grad=0, device=cpu) = onnx::AveragePool[ceil_mode=0, count_include_pad=1, kernel_shape=[2, 1], pads=[0, 0, 0, 0], strides=[2, 1], onnx_name=\"/model/features/features.26/AveragePool\"](%/model/features/features.25/Relu_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.pooling.AvgPool2d::features.26 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/pooling.py:635:0\n",
      "  %/model/features/features.27/Conv_output_0 : Float(*, 512, 64, 128, strides=[4194304, 8192, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.27/Conv\"](%/model/features/features.26/AveragePool_output_0, %onnx::Conv_204, %onnx::Conv_205), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.27 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/model/features/features.29/Relu_output_0 : Float(*, 512, 64, 128, strides=[4194304, 8192, 128, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/model/features/features.29/Relu\"](%/model/features/features.27/Conv_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.29 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/functional.py:1469:0\n",
      "  %/model/features/features.30/Conv_output_0 : Float(*, 512, 64, 128, strides=[4194304, 8192, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.30/Conv\"](%/model/features/features.29/Relu_output_0, %onnx::Conv_207, %onnx::Conv_208), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.30 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/model/features/features.32/Relu_output_0 : Float(*, 512, 64, 128, strides=[4194304, 8192, 128, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/model/features/features.32/Relu\"](%/model/features/features.30/Conv_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.32 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/functional.py:1469:0\n",
      "  %/model/features/features.33/Conv_output_0 : Float(*, 512, 64, 128, strides=[4194304, 8192, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.33/Conv\"](%/model/features/features.32/Relu_output_0, %onnx::Conv_210, %onnx::Conv_211), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.33 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/model/features/features.35/Relu_output_0 : Float(*, 512, 64, 128, strides=[4194304, 8192, 128, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/model/features/features.35/Relu\"](%/model/features/features.33/Conv_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.35 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/functional.py:1469:0\n",
      "  %/model/features/features.36/Conv_output_0 : Float(*, 512, 64, 128, strides=[4194304, 8192, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.36/Conv\"](%/model/features/features.35/Relu_output_0, %onnx::Conv_213, %onnx::Conv_214), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.36 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/model/features/features.38/Relu_output_0 : Float(*, 512, 64, 128, strides=[4194304, 8192, 128, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/model/features/features.38/Relu\"](%/model/features/features.36/Conv_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.38 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/functional.py:1469:0\n",
      "  %/model/features/features.39/AveragePool_output_0 : Float(*, 512, 32, 128, strides=[2097152, 4096, 128, 1], requires_grad=0, device=cpu) = onnx::AveragePool[ceil_mode=0, count_include_pad=1, kernel_shape=[2, 1], pads=[0, 0, 0, 0], strides=[2, 1], onnx_name=\"/model/features/features.39/AveragePool\"](%/model/features/features.38/Relu_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.pooling.AvgPool2d::features.39 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/pooling.py:635:0\n",
      "  %/model/features/features.40/Conv_output_0 : Float(*, 512, 32, 128, strides=[2097152, 4096, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.40/Conv\"](%/model/features/features.39/AveragePool_output_0, %onnx::Conv_216, %onnx::Conv_217), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.40 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/model/features/features.42/Relu_output_0 : Float(*, 512, 32, 128, strides=[2097152, 4096, 128, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/model/features/features.42/Relu\"](%/model/features/features.40/Conv_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.42 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/functional.py:1469:0\n",
      "  %/model/features/features.43/Conv_output_0 : Float(*, 512, 32, 128, strides=[2097152, 4096, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.43/Conv\"](%/model/features/features.42/Relu_output_0, %onnx::Conv_219, %onnx::Conv_220), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.43 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/model/features/features.45/Relu_output_0 : Float(*, 512, 32, 128, strides=[2097152, 4096, 128, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/model/features/features.45/Relu\"](%/model/features/features.43/Conv_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.45 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/functional.py:1469:0\n",
      "  %/model/features/features.46/Conv_output_0 : Float(*, 512, 32, 128, strides=[2097152, 4096, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.46/Conv\"](%/model/features/features.45/Relu_output_0, %onnx::Conv_222, %onnx::Conv_223), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.46 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/model/features/features.48/Relu_output_0 : Float(*, 512, 32, 128, strides=[2097152, 4096, 128, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/model/features/features.48/Relu\"](%/model/features/features.46/Conv_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.48 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/functional.py:1469:0\n",
      "  %/model/features/features.49/Conv_output_0 : Float(*, 512, 32, 128, strides=[2097152, 4096, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/model/features/features.49/Conv\"](%/model/features/features.48/Relu_output_0, %onnx::Conv_225, %onnx::Conv_226), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.49 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/model/features/features.51/Relu_output_0 : Float(*, 512, 32, 128, strides=[2097152, 4096, 128, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/model/features/features.51/Relu\"](%/model/features/features.49/Conv_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.51 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/functional.py:1469:0\n",
      "  %/model/features/features.52/AveragePool_output_0 : Float(*, 512, 32, 128, strides=[2097152, 4096, 128, 1], requires_grad=0, device=cpu) = onnx::AveragePool[ceil_mode=0, count_include_pad=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/model/features/features.52/AveragePool\"](%/model/features/features.51/Relu_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.container.Sequential::features/torch.nn.modules.pooling.AvgPool2d::features.52 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/pooling.py:635:0\n",
      "  %/model/last_conv_1x1/Conv_output_0 : Float(*, 256, 32, 128, strides=[1048576, 4096, 128, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/model/last_conv_1x1/Conv\"](%/model/features/features.52/AveragePool_output_0, %model.last_conv_1x1.weight, %model.last_conv_1x1.bias), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model/torch.nn.modules.conv.Conv2d::last_conv_1x1 # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/model/Transpose_output_0 : Float(*, 256, 128, 32, strides=[1048576, 4096, 1, 128], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name=\"/model/Transpose\"](%/model/last_conv_1x1/Conv_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/vietocr/model/backbone/vgg.py:46:0\n",
      "  %/model/Shape_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/model/Shape\"](%/model/Transpose_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/vietocr/model/backbone/vgg.py:48:0\n",
      "  %/model/Constant_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/model/Constant\"](), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/vietocr/model/backbone/vgg.py:48:0\n",
      "  %/model/Constant_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/model/Constant_1\"](), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/vietocr/model/backbone/vgg.py:48:0\n",
      "  %/model/Constant_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name=\"/model/Constant_2\"](), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/vietocr/model/backbone/vgg.py:48:0\n",
      "  %/model/Slice_output_0 : Long(2, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/model/Slice\"](%/model/Shape_output_0, %/model/Constant_1_output_0, %/model/Constant_2_output_0, %/model/Constant_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/vietocr/model/backbone/vgg.py:48:0\n",
      "  %/model/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/model/Constant_3\"](), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/vietocr/model/backbone/vgg.py:48:0\n",
      "  %/model/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/model/Concat\"](%/model/Slice_output_0, %/model/Constant_3_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/vietocr/model/backbone/vgg.py:48:0\n",
      "  %/model/Reshape_output_0 : Float(*, *, *, strides=[1048576, 4096, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name=\"/model/Reshape\"](%/model/Transpose_output_0, %/model/Concat_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/vietocr/model/backbone/vgg.py:48:0\n",
      "  %OUTPUT : Float(33, *, *, strides=[1, 1048576, 4096], requires_grad=0, device=cpu) = onnx::Transpose[perm=[-1, 0, 1], onnx_name=\"/model/Transpose_1\"](%/model/Reshape_output_0), scope: vietocr.model.backbone.cnn.CNN::/vietocr.model.backbone.vgg.Vgg::model # /home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/vietocr/model/backbone/vgg.py:50:0\n",
      "  return (%OUTPUT)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/onnx/symbolic_opset9.py:4662: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with GRU can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n",
      "/home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/vietocr/model/seqmodel/seq2seq.py:93: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert (output == hidden).all()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "# CNN part\n",
    "def convert_cnn_part(img, save_path, model, max_seq_length = 128, sos_token = 1, eos_token = 2): \n",
    "    with torch.no_grad(): \n",
    "        src = model.cnn(img)\n",
    "        torch.onnx.export(model.cnn, \n",
    "                          img, \n",
    "                          save_path, \n",
    "                          export_params = True, \n",
    "                          do_constant_folding = True, \n",
    "                          verbose = True, \n",
    "                          input_names = ['IMAGE'], \n",
    "                          output_names = ['OUTPUT'], \n",
    "                          dynamic_axes = {'IMAGE': {0: 'batch'}, 'OUTPUT': {1: 'batch'}}) # channel output of cnn in the 2nd dimension\n",
    "     \n",
    "    return src\n",
    "\n",
    "# Encoder part\n",
    "def convert_encoder_part(model, src, save_path): \n",
    "    encoder_outputs, hidden = model.transformer.encoder(src) \n",
    "    torch.onnx.export(model.transformer.encoder, \n",
    "                      src, \n",
    "                      save_path, \n",
    "                      export_params = True, \n",
    "                      opset_version = 11, \n",
    "                      do_constant_folding = True, \n",
    "                      input_names  = ['src'], \n",
    "                      output_names = ['encoder_outputs', 'hidden'], \n",
    "                      dynamic_axes = {'src' : {0 : \"channel_input\"}, \n",
    "                                      'encoder_outputs' : {0 : 'channel_output'}}) \n",
    "    return hidden, encoder_outputs\n",
    "\n",
    "# Decoder part\n",
    "def convert_decoder_part(model, tgt, hidden, encoder_outputs, save_path):\n",
    "    tgt = tgt[-1]\n",
    "    print(tgt)\n",
    "    torch.onnx.export(  model.transformer.decoder,\n",
    "                        (tgt, hidden, encoder_outputs),\n",
    "                        save_path,\n",
    "                        export_params = True,\n",
    "                        opset_version = 11,\n",
    "                        do_constant_folding = True,\n",
    "                        input_names = ['tgt', 'hidden', 'encoder_outputs'],\n",
    "                        output_names = ['output', 'hidden_out', 'last'],\n",
    "                        dynamic_axes = {'encoder_outputs' : {0 : \"channel_input\"}, \n",
    "                                        'last' : {0 : 'channel_output'}})\n",
    "\n",
    "\n",
    "# Export model\n",
    "img = torch.rand(1, 3, 512, 512)   # input tensor of torch model (N x C x H x W)\n",
    "src = convert_cnn_part(img, 'models/ocr_cnn/1/model.onnx', model)\n",
    "\n",
    "hidden, encoder_outputs = convert_encoder_part(model, src, 'models/ocr_encoder/1/model.onnx')\n",
    "\n",
    "device = img.device\n",
    "tgt = torch.LongTensor([[1] * len(img)]).to(device)\n",
    "convert_decoder_part(model, tgt, hidden, encoder_outputs, 'models/ocr_decoder/1/model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "VietOCR.forward() missing 2 required positional arguments: 'tgt_input' and 'tgt_key_padding_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/craftdet/lib/python3.11/site-packages/torchsummary/torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "File \u001b[0;32m~/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/craftdet/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: VietOCR.forward() missing 2 required positional arguments: 'tgt_input' and 'tgt_key_padding_mask'"
     ]
    }
   ],
   "source": [
    "summary.summary(model, (3, 512, 512), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script testing tracing\n",
    "code: https://pytorch.org/tutorials//beginner/Intro_to_TorchScript_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionGate(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        if x.sum() > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return -x\n",
    "\n",
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self, dg):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.dg = dg\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        return new_h, new_h\n",
    "    \n",
    "class MyCell2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dg = MyDecisionGate()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        return new_h, new_h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, h = torch.rand(3, 4), torch.rand(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    argument_1: Tensor) -> Tensor:\n",
      "  return torch.neg(argument_1)\n",
      "\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = torch.add((dg).forward((linear).forward(x, ), ), h)\n",
      "  _1 = torch.tanh(_0)\n",
      "  return (_1, _1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_964/1475766357.py:3: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if x.sum() > 0:\n"
     ]
    }
   ],
   "source": [
    "my_cell = MyCell(MyDecisionGate())\n",
    "traced_cell = torch.jit.trace(my_cell, (x, h))\n",
    "print(traced_cell.dg.code)\n",
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    argument_1: Tensor) -> Tensor:\n",
      "  return torch.neg(argument_1)\n",
      "\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = torch.add((dg).forward((linear).forward(x, ), ), h)\n",
      "  _1 = torch.tanh(_0)\n",
      "  return (_1, _1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_964/1475766357.py:3: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if x.sum() > 0:\n"
     ]
    }
   ],
   "source": [
    "my_cell2 = MyCell2()\n",
    "traced_cell2 = torch.jit.trace(my_cell2, (x, h))\n",
    "print(traced_cell2.dg.code)\n",
    "print(traced_cell2.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  if bool(torch.gt(torch.sum(x), 0)):\n",
      "    _0 = x\n",
      "  else:\n",
      "    _0 = torch.neg(x)\n",
      "  return _0\n",
      "\n",
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  dg = self.dg\n",
      "  linear = self.linear\n",
      "  _0 = torch.add((dg).forward((linear).forward(x, ), ), h)\n",
      "  new_h = torch.tanh(_0)\n",
      "  return (new_h, new_h)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hungnq/.conda/envs/craftdet/lib/python3.11/site-packages/torch/jit/_script.py:1277: UserWarning: `optimize` is deprecated and has no effect. Use `with torch.jit.optimized_execution() instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "script_cell2 = torch.jit.script(my_cell2, (x, h))\n",
    "print(script_cell2.dg.code)\n",
    "print(script_cell2.code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "craftdet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
